Overall, the choice of model depends on the specific task and the degree of code-mixing in the data. 
For tasks that involve a high degree of code-mixing, m-BeRT may be a better choice, while for tasks that involve mostly monolingual text with occasional code-mixing, BeRT may be more appropriate.




